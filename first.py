# -*- coding: utf-8 -*-
"""first.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJND4boFxEFojl_PZ0YyHgi1YmkhS_Dz
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files
uploaded=files.upload()
print(uploaded)

df_train=pd.read_csv("/content/train.csv")
df_test=pd.read_csv("/content/test.csv")

df_train.head(10)

df_train.shape

df_train.info()

df_train.describe()

df_train.columns

l1=['PassengerId','Name','Ticket']

df_test.drop(l1,axis=1,inplace=True)

df_train.drop(l1,axis=1,inplace=True)

df_train.head()

df_train.nunique()

df_train['Embarked'].unique()

df_train.isnull()

df_train.isnull().sum()

df_train.shape

l2=['Cabin']
df_train.drop(l2,axis=1,inplace=True)
df_test.drop(l2,axis=1,inplace=True)



df_train.head()

df_train['Age']

df_train.isnull().sum()

df_test.isnull().sum()

df_train['Age'].fillna(df_train['Age'].mean(),inplace=True)
df_test['Age'].fillna(df_test['Age'].mean(),inplace=True)

df_train.isnull().sum()
# df_test.isnull().sum()

df_train['Embarked'].unique()

df_train['Embarked'].mode()

df_train.dropna(inplace=True)
df_test.dropna(inplace=True)

df_train.isnull().sum()

df_test.isnull().sum()

"""#Data Cleaning is DOne"""

def graph(s):
  sur=df_train[df_train['Survived']==1][s].value_counts()
  passed=df_train[df_train['Survived']==0][s].value_counts()

  df=pd.DataFrame([sur,passed])
  df.plot(kind='bar',stacked=True)

graph('Sex')

graph('Embarked')

"""Label Encoding

"""

df_train.head()

from sklearn.preprocessing import LabelEncoder
le_S=LabelEncoder()
le_E=LabelEncoder()

df_train['Sex']=le_S.fit_transform(df_train['Sex'])
df_train['Embarked']=le_E.fit_transform(df_train['Embarked'])

df_train.head()

df_test['Sex']=le_S.transform(df_test['Sex'])
df_test['Embarked']=le_E.transform(df_test['Embarked'])

df_test.head()

"""fit, f_t, transform"""

le_S.classes_

le_E.classes_

"""standarScaling is req. to increase the computational power ,
Data scaling is req.
"""

X_train=df_train.iloc[:,1: ].values # take out specific column from dataframe and convert it to numpy array with slicing
y_train=df_train.iloc[:,0].values
X_test=df_test.values

X_train.shape,y_train.shape,type(X_train)

from sklearn.preprocessing import StandardScaler

scale_x = StandardScaler()

X_train = scale_x.fit_transform(X_train)  # learn mean & std
X_test  = scale_x.transform(X_test)       # use SAME scaling

X_train[:10,:]

"""Standard Scaling rescales features so they have mean 0 and standard deviation 1, helping models learn fairly.

# Model Fiting
"""

from sklearn.neighbors import KNeighborsClassifier

clf =KNeighborsClassifier()
clf.fit(X_train,y_train)  # magic line

pred=clf.predict(X_train)

# pred

(pred==y_train).sum()

y_train.shape,pred.shape

(pred==y_train).sum()/pred.shape